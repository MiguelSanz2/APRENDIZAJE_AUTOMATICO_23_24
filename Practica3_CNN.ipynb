{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelSanz2/APRENDIZAJE_AUTOMATICO_23_24/blob/main/Practica3_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# PRÁCTICA 3:\n",
        "\n",
        "REDES DE NEURONAS CONVOLUCIONALES\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Grupo 07:**   *Componentes:*\n",
        "\n",
        "*   Carlos Adaro Cacho\n",
        "*   Juan Rivera Sánchez\n",
        "*   Miguel Sanz Almau\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RketqzxgZbOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introducción**\n",
        "\n",
        "En este código, se muestra cómo utilizamos TensorFlow para implementar una red neuronal convolucional (CNN) para la clasificación de imágenes utilizando el conjunto de datos CIFAR-100. La CNN es una arquitectura de red neuronal especialmente diseñada para procesar datos de imágenes y ha demostrado ser muy efectiva en tareas de clasificación de imágenes."
      ],
      "metadata": {
        "id": "oONF3aA6dS0m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bvhlsK6luC2R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 1:**\n",
        "\n",
        "Descargar el conjunto de datos CIFAR-100\n",
        "En este paso, descargamos el conjunto de datos CIFAR-100 utilizando la función cifar100.load_data(). El conjunto de datos se divide en datos de entrenamiento y datos de prueba, que se almacenan en las variables x_train, y_train, x_test y y_test."
      ],
      "metadata": {
        "id": "VYz6QcMrcWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "metadata": {
        "id": "MwMO_wjYcPUh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 2:**\n",
        "\n",
        "Preprocesar los datos\n",
        "En este paso, realizamos el preprocesamiento de los datos dividiendo los valores de los píxeles entre 255.0 para normalizarlos en el rango de 0 a 1. Esto ayudará a mejorar la convergencia del modelo durante el entrenamiento."
      ],
      "metadata": {
        "id": "kg8xHQiIb-xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "zAi0X7SbcjQ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 3:**\n",
        "\n",
        "Definir la estructura de la red neuronal convolucional\n",
        "En este paso, se define la estructura de la red neuronal convolucional utilizando la clase Sequential de TensorFlow. Se agregan capas convolucionales, capas de agrupación máxima, capas de aplanamiento y capas completamente conectadas para construir la arquitectura de la CNN."
      ],
      "metadata": {
        "id": "b8CtmE-TdymG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='softmax'))"
      ],
      "metadata": {
        "id": "YUsNEvgLcr7K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 4:**\n",
        "\n",
        "Compilar el modelo\n",
        "En este paso, se compila el modelo especificando el optimizador y la función de pérdida. En este caso, se utiliza el optimizador Adam y la función de pérdida de entropía cruzada escasa."
      ],
      "metadata": {
        "id": "Fb_pj5Abd5zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jX9rAypzczF6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 5:**\n",
        "\n",
        "Programación del aprendizaje: El código define una función lr_schedule que ajusta la tasa de aprendizaje durante el entrenamiento. Esta función se utiliza como argumento en el callback LearningRateScheduler, que ajusta la tasa de aprendizaje según el número de épocas."
      ],
      "metadata": {
        "id": "sB5UPywDd_S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 10:\n",
        "        lr *= 0.4\n",
        "    elif epoch > 25:\n",
        "        lr *= 0.2\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test), callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOgdY94Wc2fb",
        "outputId": "7ec12bca-8f36-4bf2-d144-dc962a193dac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 11s 21ms/step - loss: 4.1438 - accuracy: 0.1152 - val_loss: 4.3750 - val_accuracy: 0.0771 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 3.2366 - accuracy: 0.2284 - val_loss: 2.8210 - val_accuracy: 0.3028 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 2.7864 - accuracy: 0.3025 - val_loss: 2.5067 - val_accuracy: 0.3618 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 2.5263 - accuracy: 0.3530 - val_loss: 2.2944 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 2.3569 - accuracy: 0.3902 - val_loss: 2.1418 - val_accuracy: 0.4376 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 2.2381 - accuracy: 0.4135 - val_loss: 2.0495 - val_accuracy: 0.4601 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 2.1317 - accuracy: 0.4354 - val_loss: 2.0110 - val_accuracy: 0.4659 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 2.0503 - accuracy: 0.4524 - val_loss: 1.9668 - val_accuracy: 0.4758 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.9796 - accuracy: 0.4680 - val_loss: 1.9637 - val_accuracy: 0.4790 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.9146 - accuracy: 0.4822 - val_loss: 1.8821 - val_accuracy: 0.4983 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.8576 - accuracy: 0.4958 - val_loss: 1.9073 - val_accuracy: 0.4954 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.7037 - accuracy: 0.5316 - val_loss: 1.7684 - val_accuracy: 0.5216 - lr: 4.0000e-04\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.6550 - accuracy: 0.5431 - val_loss: 1.7508 - val_accuracy: 0.5279 - lr: 4.0000e-04\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.6186 - accuracy: 0.5534 - val_loss: 1.7744 - val_accuracy: 0.5245 - lr: 4.0000e-04\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.5903 - accuracy: 0.5562 - val_loss: 1.7369 - val_accuracy: 0.5304 - lr: 4.0000e-04\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.5630 - accuracy: 0.5621 - val_loss: 1.6960 - val_accuracy: 0.5435 - lr: 4.0000e-04\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.5331 - accuracy: 0.5713 - val_loss: 1.7310 - val_accuracy: 0.5346 - lr: 4.0000e-04\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.4981 - accuracy: 0.5792 - val_loss: 1.7272 - val_accuracy: 0.5343 - lr: 4.0000e-04\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.4773 - accuracy: 0.5830 - val_loss: 1.6805 - val_accuracy: 0.5456 - lr: 4.0000e-04\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.4539 - accuracy: 0.5880 - val_loss: 1.6798 - val_accuracy: 0.5505 - lr: 4.0000e-04\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.4360 - accuracy: 0.5919 - val_loss: 1.7267 - val_accuracy: 0.5377 - lr: 4.0000e-04\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.4180 - accuracy: 0.5990 - val_loss: 1.6757 - val_accuracy: 0.5497 - lr: 4.0000e-04\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 1.3954 - accuracy: 0.6007 - val_loss: 1.6932 - val_accuracy: 0.5429 - lr: 4.0000e-04\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.3833 - accuracy: 0.6086 - val_loss: 1.6619 - val_accuracy: 0.5551 - lr: 4.0000e-04\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.3573 - accuracy: 0.6098 - val_loss: 1.6685 - val_accuracy: 0.5567 - lr: 4.0000e-04\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 1.3310 - accuracy: 0.6175 - val_loss: 1.6535 - val_accuracy: 0.5575 - lr: 4.0000e-04\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.3169 - accuracy: 0.6213 - val_loss: 1.8025 - val_accuracy: 0.5246 - lr: 4.0000e-04\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 1.3058 - accuracy: 0.6237 - val_loss: 1.7144 - val_accuracy: 0.5445 - lr: 4.0000e-04\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 1.2889 - accuracy: 0.6285 - val_loss: 1.6487 - val_accuracy: 0.5543 - lr: 4.0000e-04\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 1.2736 - accuracy: 0.6304 - val_loss: 1.6561 - val_accuracy: 0.5555 - lr: 4.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 6:**\n",
        "\n",
        "Evaluar el modelo\n",
        "En este paso, se evalúa el rendimiento del modelo utilizando los datos de prueba. Se calcula la pérdida y la precisión del modelo en los datos de prueba."
      ],
      "metadata": {
        "id": "BTPGsJNveGYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print('Precisión en los datos de prueba:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrFjnzUNc6K6",
        "outputId": "deb86060-e5df-4ad7-cafd-99772a69d2f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 1.6561 - accuracy: 0.5555 - 1s/epoch - 3ms/step\n",
            "Precisión en los datos de prueba: 0.5554999709129333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 7:**\n",
        "\n",
        "Realizar predicciones\n",
        "En este paso, se realiza una predicción utilizando el modelo entrenado en una imagen seleccionada al azar del conjunto de datos de prueba. Se muestra la etiqueta verdadera y la etiqueta predicha para compararlas."
      ],
      "metadata": {
        "id": "psbOVJh8eLtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "model.summary()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Seleccionar una imagen al azar del conjunto de datos de prueba\n",
        "random_index = np.random.randint(0, len(x_test))\n",
        "random_image = x_test[random_index]\n",
        "true_label = y_test[random_index]\n",
        "\n",
        "# Realizar la predicción con el modelo\n",
        "predicted_label = np.argmax(model.predict(np.expand_dims(random_image, axis=0)), axis=-1)\n",
        "\n",
        "# Mostrar la imagen y su etiqueta\n",
        "print(f'Etiqueta verdadera: {true_label}')\n",
        "print(f'Etiqueta predicha: {predicted_label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPNpUXHec8va",
        "outputId": "2f31e9bd-a331-4b8e-bb21-a31919693810"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               51300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2217348 (8.46 MB)\n",
            "Trainable params: 2215940 (8.45 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Etiqueta verdadera: [36]\n",
            "Etiqueta predicha: [36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Explicación del model.summary()**\n",
        "\n",
        "* El entrenamiento se llevó a cabo durante 30 épocas (Epoch 1/30 hasta Epoch 30/30).\n",
        "\n",
        "* Se realizaron 391 iteraciones (batches) por época.\n",
        "\n",
        "* El tiempo de ejecución por iteración fue de alrededor de 8-12 segundos por lote (step).\n",
        "\n",
        "* La función de pérdida (loss) en el conjunto de entrenamiento disminuyó de 4.0970 a 1.3304, lo cual indica que el modelo mejoró en la capacidad de hacer predicciones conforme avanzaba el entrenamiento.\n",
        "\n",
        "* La precisión (accuracy) en el conjunto de entrenamiento aumentó de 0.1208 a 0.6185.\n",
        "\n",
        "* Se proporcionan métricas similares para el conjunto de validación (val_loss y val_accuracy).\n",
        "\n",
        "2. **Optimizador y Tasa de Aprendizaje (LearningRateScheduler):**\n",
        "\n",
        "* El optimizador utilizado parece ser un optimizador basado en gradiente descendente con una tasa de aprendizaje inicial de 0.001.\n",
        "\n",
        "* A partir de la Epoch 12/30, la tasa de aprendizaje disminuyó a 0.0004.\n",
        "\n",
        "3. **Descripción del Modelo:**\n",
        "\n",
        "* El modelo es de tipo secuencial (Sequential) y tiene varias capas, incluyendo capas convolucionales (Conv2D), capas de normalización (BatchNormalization), capas de agrupación máxima (MaxPooling2D), capas de abandono (Dropout), y capas densas (Dense).\n",
        "\n",
        "* La última capa densa tiene 100 unidades de salida, lo que sugiere que este modelo se entrenó para clasificar imágenes en 100 clases diferentes.\n",
        "\n",
        "4. **Parámetros del Modelo:**\n",
        "\n",
        "* El modelo tiene un total de 2,217,348 parámetros, de los cuales 2,215,940 son entrenables y 1,408 son no entrenables.\n",
        "\n",
        "En resumen, el modelo fue entrenado para la clasificación de imágenes utilizando el algoritmo de retropropagación (backpropagation) a través de 30 épocas, y parece haber mejorado en términos de pérdida y precisión a lo largo del tiempo. La disminución de la tasa de aprendizaje aplicando (LearningRateScheduler) después de la Epoch 12/30 sugiere que se puede estar utilizando un esquema de ajuste de tasa de aprendizaje para una convergencia más efectiva."
      ],
      "metadata": {
        "id": "txGAfE8FmWuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Conceptos clave**\n",
        "\n",
        "\n",
        "Conjunto de datos CIFAR-100: El conjunto de datos CIFAR-100 es un conjunto de imágenes de 32x32 píxeles que se divide en 100 clases diferentes. Cada imagen está etiquetada con una de las 100 clases.\n",
        "\n",
        "Preprocesamiento de datos: Antes de alimentar los datos a la red neuronal, es común realizar un preprocesamiento para normalizar los valores de los píxeles y mejorar la convergencia del modelo.\n",
        "\n",
        "Estructura de la red neuronal convolucional: La CNN utilizada en este código consta de varias capas convolucionales, capas de agrupación máxima, capas de aplanamiento y capas completamente conectadas. Estas capas se combinan para extraer características de las imágenes y realizar la clasificación.\n",
        "\n",
        "Compilación y entrenamiento del modelo: Después de definir la estructura de la red neuronal, se compila el modelo especificando el optimizador y la función de pérdida. Luego, el modelo se entrena utilizando los datos de entrenamiento y se valida utilizando los datos de prueba.\n",
        "\n",
        "Evaluación y predicción del modelo: Una vez entrenado el modelo, se evalúa su rendimiento utilizando los datos de prueba. También se pueden realizar predicciones utilizando el modelo entrenado en nuevas imágenes."
      ],
      "metadata": {
        "id": "NRKxMEsdb74Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gestión del grupo**\n",
        "\n",
        "Durante el trabajo realizado por el grupo hemos primero programado el código de la red neuronal convolucional y tras ello, hemos ido entrenando por separado la red modificando diferentes elementos del código así como la tasa de aprendizaje, el Dropout, número de capas y épocas,etc.Trabajando para conseguir un aumento de la precisión (‘val_accuracy’) llegamos a obtener entre 0.55-0.56,\n",
        "\n",
        "A partir de ese resultado hemos conseguido que la etiqueta verdadera coincida con la clase predicha.\n",
        "Para la memoria nos hemos dividido la implementación de los comentarios en: introducción, pasos del código, conceptos clave y explicación de nuestro ‘model.summary()’."
      ],
      "metadata": {
        "id": "vFJQvq2hoMMh"
      }
    }
  ]
}